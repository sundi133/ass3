DecisionTree using Info Gain:
The decision tree is printed in terms of  equivalent set of rules as learned from the dataset.The attribute VISIBILITY is chosen in depth 1 as it has the highest information gain out of all the atributes . Similarly the attributes which has the highest info gain in successive levels is chosen for partitioning.

Tree using info gain:

if( VISIBILITY == "yes") {
	if( ERROR == "XL") {
		AUTO = "1";
	} else if( ERROR == "LX") {
		AUTO = "1";
	} else if( ERROR == "MM") {
		if( STABILItY == "stab") {
			if( SIGN == "pp") {
				if( MAGNITUDE == "Medium") {
					AUTO = "2";
				} else if( MAGNITUDE == "Strong") {
					if( WIND == "head") {
						AUTO = "1";
					} else if( WIND == "tail") {
							AUTO = "2";
					}
				} else if( MAGNITUDE == "OutOfRange") {
					AUTO = "1";
				} else 	if( MAGNITUDE == "Low") {
					AUTO = "2";
				}
			} else if( SIGN == "nn") {
				AUTO = "1";
			}
		} else if( STABILItY == "xstab") {
			AUTO = "1";
		}
	} else if( ERROR == "SS") {
		if( STABILItY == "stab") {
			if( MAGNITUDE == "Medium") {
				AUTO = "2";
			} else if( MAGNITUDE == "Strong") {
				AUTO = "2";
			} else if( MAGNITUDE == "OutOfRange") {
				AUTO = "1";
			} else if( MAGNITUDE == "Low") {
				AUTO = "2";
			}
		} else  if( STABILItY == "xstab") {
			AUTO = "1";
		}
	}
} else if( VISIBILITY == "no") {
		AUTO = "2";
}
